{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e464f457",
   "metadata": {},
   "source": [
    "\n",
    "# Benchmark Runtime and Memory Overview\n",
    "\n",
    "This notebook loads QuASAr benchmark runs from the SQLite database produced by the\n",
    "benchmark sweep helpers and visualises runtime and peak memory consumption trends\n",
    "as a function of qubit count and circuit depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7165da8",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "Update `DB_PATH` below if your benchmark database lives somewhere else. The\n",
    "default points at `benchmarks.db` in the repository root, which is where the\n",
    "benchmark sweep helpers persist their results by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa526e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as exc:  # pragma: no cover - notebook guard\n",
    "    raise ImportError(\n",
    "        \"This notebook requires pandas. Install it with `pip install pandas`.\"\n",
    "    ) from exc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd183c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_PATH = Path(\"benchmarks.db\")\n",
    "if not DB_PATH.exists():  # pragma: no cover - user environment check\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find {DB_PATH}. Update `DB_PATH` to the location of your benchmark database.\"\n",
    "    )\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c703036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_quasar_runs(db_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load QuASAr benchmark runs that have runtime or memory statistics.\"\"\"\n",
    "    columns = [\n",
    "        \"id\",\n",
    "        \"created_at\",\n",
    "        \"family\",\n",
    "        \"varying\",\n",
    "        \"varying_value\",\n",
    "        \"num_qubits\",\n",
    "        \"depth\",\n",
    "        \"exec_wall_s\",\n",
    "        \"peak_rss_bytes\",\n",
    "    ]\n",
    "    query = (\n",
    "        \"SELECT {cols} FROM quasar_runs \"\n",
    "        \"WHERE exec_wall_s IS NOT NULL OR peak_rss_bytes IS NOT NULL\"\n",
    "    ).format(cols=\", \".join(columns))\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        frame = pd.read_sql_query(query, conn, parse_dates=[\"created_at\"])\n",
    "    frame[\"peak_rss_gib\"] = frame[\"peak_rss_bytes\"].astype(float) / 1024 ** 3\n",
    "    return frame\n",
    "\n",
    "\n",
    "def summarise_by_metric(\n",
    "    frame: pd.DataFrame, *, axis: str, metric: str, agg: str = \"mean\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Aggregate the selected metric over the requested axis and circuit family.\"\"\"\n",
    "    if axis not in {\"num_qubits\", \"depth\"}:\n",
    "        raise ValueError(\"axis must be either 'num_qubits' or 'depth'\")\n",
    "    grouped = (\n",
    "        frame.dropna(subset=[metric])\n",
    "        .groupby([\"family\", axis], dropna=False)\n",
    "        .agg({metric: agg})\n",
    "        .rename(columns={metric: f\"{metric}_{agg}\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def plot_metric(grouped: pd.DataFrame, *, axis: str, metric_label: str, ylabel: str) -> None:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    for family, family_frame in grouped.groupby(\"family\"):\n",
    "        family_frame = family_frame.sort_values(axis)\n",
    "        ax.plot(\n",
    "            family_frame[axis],\n",
    "            family_frame.iloc[:, 2],\n",
    "            marker=\"o\",\n",
    "            label=family,\n",
    "        )\n",
    "    ax.set_xlabel(axis.replace(\"_\", \" \").title())\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(f\"{metric_label} vs. {axis.replace('_', ' ').title()}\")\n",
    "    ax.legend(title=\"Circuit family\", loc=\"best\")\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e40fd",
   "metadata": {},
   "source": [
    "\n",
    "## Load benchmark data\n",
    "\n",
    "The cell below inspects the database and provides a preview of the records that\n",
    "include runtime or memory statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quasar_runs = load_quasar_runs(DB_PATH)\n",
    "quasar_runs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff5cb5",
   "metadata": {},
   "source": [
    "\n",
    "## Runtime and memory trends vs. qubit count\n",
    "\n",
    "The following plots compute the mean runtime and peak resident-set size for\n",
    "runs grouped by circuit family and qubit count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77259016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runtime_vs_qubits = summarise_by_metric(quasar_runs, axis=\"num_qubits\", metric=\"exec_wall_s\")\n",
    "memory_vs_qubits = summarise_by_metric(quasar_runs, axis=\"num_qubits\", metric=\"peak_rss_gib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badeb2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(\n",
    "    runtime_vs_qubits,\n",
    "    axis=\"num_qubits\",\n",
    "    metric_label=\"Runtime (s)\",\n",
    "    ylabel=\"Mean execution wall-clock time (s)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab568e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(\n",
    "    memory_vs_qubits,\n",
    "    axis=\"num_qubits\",\n",
    "    metric_label=\"Peak memory (GiB)\",\n",
    "    ylabel=\"Mean peak RSS (GiB)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d028d5",
   "metadata": {},
   "source": [
    "\n",
    "## Runtime and memory trends vs. circuit depth\n",
    "\n",
    "Similarly, we can look at the same metrics grouped by circuit depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cf323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runtime_vs_depth = summarise_by_metric(quasar_runs, axis=\"depth\", metric=\"exec_wall_s\")\n",
    "memory_vs_depth = summarise_by_metric(quasar_runs, axis=\"depth\", metric=\"peak_rss_gib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(\n",
    "    runtime_vs_depth,\n",
    "    axis=\"depth\",\n",
    "    metric_label=\"Runtime (s)\",\n",
    "    ylabel=\"Mean execution wall-clock time (s)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7135c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(\n",
    "    memory_vs_depth,\n",
    "    axis=\"depth\",\n",
    "    metric_label=\"Peak memory (GiB)\",\n",
    "    ylabel=\"Mean peak RSS (GiB)\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
